{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "12518019-7b77-4321-b40c-bb4f58043c68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Math</th>\n",
       "      <th>Reading</th>\n",
       "      <th>Writing</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>48</td>\n",
       "      <td>68</td>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>62</td>\n",
       "      <td>81</td>\n",
       "      <td>72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>79</td>\n",
       "      <td>80</td>\n",
       "      <td>78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>76</td>\n",
       "      <td>83</td>\n",
       "      <td>79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>59</td>\n",
       "      <td>64</td>\n",
       "      <td>62</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Math  Reading  Writing\n",
       "0    48       68       63\n",
       "1    62       81       72\n",
       "2    79       80       78\n",
       "3    76       83       79\n",
       "4    59       64       62"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To-Do-1\n",
    "import pandas as pd\n",
    "data = pd.read_csv(\"C:/Users/Natsu Rohit/Downloads/student.csv\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b00811dc-46d4-48b8-b5ce-a336825d4271",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Math</th>\n",
       "      <th>Reading</th>\n",
       "      <th>Writing</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>72</td>\n",
       "      <td>74</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>73</td>\n",
       "      <td>86</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>89</td>\n",
       "      <td>87</td>\n",
       "      <td>94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>83</td>\n",
       "      <td>82</td>\n",
       "      <td>78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>66</td>\n",
       "      <td>66</td>\n",
       "      <td>72</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Math  Reading  Writing\n",
       "995    72       74       70\n",
       "996    73       86       90\n",
       "997    89       87       94\n",
       "998    83       82       78\n",
       "999    66       66       72"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9a75b1c2-a728-4c22-8ebf-72d7c6e887ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1000 entries, 0 to 999\n",
      "Data columns (total 3 columns):\n",
      " #   Column   Non-Null Count  Dtype\n",
      "---  ------   --------------  -----\n",
      " 0   Math     1000 non-null   int64\n",
      " 1   Reading  1000 non-null   int64\n",
      " 2   Writing  1000 non-null   int64\n",
      "dtypes: int64(3)\n",
      "memory usage: 23.6 KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6939a878-39aa-4bf5-acd8-6c1daa27eebb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Math</th>\n",
       "      <th>Reading</th>\n",
       "      <th>Writing</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>67.290000</td>\n",
       "      <td>69.872000</td>\n",
       "      <td>68.616000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>15.085008</td>\n",
       "      <td>14.657027</td>\n",
       "      <td>15.241287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>13.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>14.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>58.000000</td>\n",
       "      <td>60.750000</td>\n",
       "      <td>58.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>68.000000</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>69.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>78.000000</td>\n",
       "      <td>81.000000</td>\n",
       "      <td>79.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Math      Reading      Writing\n",
       "count  1000.000000  1000.000000  1000.000000\n",
       "mean     67.290000    69.872000    68.616000\n",
       "std      15.085008    14.657027    15.241287\n",
       "min      13.000000    19.000000    14.000000\n",
       "25%      58.000000    60.750000    58.000000\n",
       "50%      68.000000    70.000000    69.500000\n",
       "75%      78.000000    81.000000    79.000000\n",
       "max     100.000000   100.000000   100.000000"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1172faa1-3f6b-4205-95cb-4307d5999a12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(800, 2) (200, 2)\n",
      "(800,) (200,)\n"
     ]
    }
   ],
   "source": [
    "# To-Do-3\n",
    "import numpy as np\n",
    "X = data.drop(\"Writing\",axis=1).values\n",
    "Y = data[\"Writing\"].values\n",
    "def train_test_split_data(X,Y,test_size=0.2,random_seed=42):\n",
    "    np.random.seed(random_seed)\n",
    "    indices = np.arange(len(X))\n",
    "    np.random.shuffle(indices)\n",
    "    test_count = int(len(X) * test_size)\n",
    "    test_indices = indices[:test_count]\n",
    "    train_indices = indices[test_count:]\n",
    "    X_train = X[train_indices]\n",
    "    X_test = X[test_indices]\n",
    "    Y_train = Y[train_indices]\n",
    "    Y_test = Y[test_indices]\n",
    "    return X_train, X_test, Y_train, Y_test\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split_data(X,Y)\n",
    "print(X_train.shape, X_test.shape)\n",
    "print(Y_train.shape, Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "75783183-609c-4b04-8e7e-d9a8a716b486",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proceed Further\n",
      "Cost function output: 0.0\n"
     ]
    }
   ],
   "source": [
    "# To-Do-4\n",
    "#Define the cost function\n",
    "def cost_function(X,Y,W):\n",
    "    \"\"\"Parameters:\n",
    "    This function finds the Mean Square Error.\n",
    "    Input Parameters:\n",
    "    X: Feature Matrix\n",
    "    Y: Target Matrix\n",
    "    W: Weight Matrix\n",
    "    Output Parameters:\n",
    "    cost: accumulated mean square error.\n",
    "    \"\"\"\n",
    "    #Convert to numpy arrays\n",
    "    X = np.array(X, dtype= float)\n",
    "    Y = np.array(Y, dtype = float).reshape(-1,1)\n",
    "    W = np.array(W, dtype = float).reshape(-1,1)\n",
    "    \n",
    "    n = len(Y)\n",
    "    #Prediction: XW\n",
    "    Y_predicted = X @ W\n",
    "    error = Y_predicted - Y\n",
    "    MSE = (1 / (n)) * np.sum(error ** 2)\n",
    "\n",
    "    return MSE\n",
    "\n",
    "# To-Do-5\n",
    "#Test case\n",
    "X_test = np.array([[1,2],[3,4],[5,6]])\n",
    "Y_test = np.array([3,7,11])\n",
    "W_test = np.array([1,1])\n",
    "cost = cost_function(X_test, Y_test, W_test)\n",
    "if cost == 0:\n",
    "    print(\"Proceed Further\")\n",
    "else:\n",
    "    print(\"Something went wrong: Reimplement a cost function\")\n",
    "print(\"Cost function output:\", cost_function(X_test, Y_test, W_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cca30ae2-c7bc-4159-874a-f4a1a8b6792c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0: Cost = 0.10788797459582472\n",
      "Iteration 100: Cost = 0.06952441576676843\n",
      "Iteration 200: Cost = 0.0614292613809287\n",
      "Iteration 300: Cost = 0.05901758461346795\n",
      "Iteration 400: Cost = 0.057792319643902336\n",
      "Iteration 500: Cost = 0.05691109058259633\n",
      "Iteration 600: Cost = 0.05619971854148787\n",
      "Iteration 700: Cost = 0.05560892326298588\n",
      "Iteration 800: Cost = 0.05511503233557687\n",
      "Iteration 900: Cost = 0.05470145694318413\n",
      "Final Parameters: [[0.20551667]\n",
      " [0.54295081]\n",
      " [0.10388027]]\n",
      "Cost History: [np.float64(0.10788797459582472), np.float64(0.10711197094660153), np.float64(0.10634880599939901), np.float64(0.10559826315680618), np.float64(0.10486012948320558), np.float64(0.1041341956428534), np.float64(0.10342025583900626), np.float64(0.1027181077540776), np.float64(0.1020275524908062), np.float64(0.10134839451441931), np.float64(0.1006804415957737), np.float64(0.1000235047554587), np.float64(0.09937739820884377), np.float64(0.09874193931205609), np.float64(0.09811694850887098), np.float64(0.09750224927850094), np.float64(0.0968976680842672), np.float64(0.09630303432313951), np.float64(0.09571818027612913), np.float64(0.09514294105952065), np.float64(0.09457715457692842), np.float64(0.09402066147216397), np.float64(0.09347330508290017), np.float64(0.09293493139511913), np.float64(0.09240538899833017), np.float64(0.09188452904154543), np.float64(0.0913722051899995), np.float64(0.09086827358260123), np.float64(0.09037259279010502), np.float64(0.08988502377398919), np.float64(0.08940542984603007), np.float64(0.08893367662855953), np.float64(0.08846963201539432), np.float64(0.08801316613342668), np.float64(0.08756415130486386), np.float64(0.08712246201010665), np.float64(0.08668797485125508), np.float64(0.08626056851623207), np.float64(0.08584012374351278), np.float64(0.08542652328745133), np.float64(0.08501965188419301), np.float64(0.0846193962181636), np.float64(0.08422564488912489), np.float64(0.08383828837978763), np.float64(0.08345721902397185), np.float64(0.08308233097530582), np.float64(0.08271352017645425), np.float64(0.08235068432886682), np.float64(0.08199372286303817), np.float64(0.08164253690927113), np.float64(0.08129702926893387), np.float64(0.08095710438620353), np.float64(0.08062266832028739), np.float64(0.08029362871811391), np.float64(0.07996989478748553), np.float64(0.0796513772706855), np.float64(0.07933798841853089), np.float64(0.07902964196486459), np.float64(0.07872625310147845), np.float64(0.07842773845346054), np.float64(0.07813401605495938), np.float64(0.0778450053253578), np.float64(0.0775606270458499), np.float64(0.07728080333641404), np.float64(0.07700545763317514), np.float64(0.07673451466614989), np.float64(0.07646790043736812), np.float64(0.07620554219936448), np.float64(0.07594736843403344), np.float64(0.07569330883184205), np.float64(0.07544329427139428), np.float64(0.07519725679934074), np.float64(0.07495512961062821), np.float64(0.07471684702908327), np.float64(0.07448234448832412), np.float64(0.0742515585129952), np.float64(0.07402442670031911), np.float64(0.0738008877019607), np.float64(0.07358088120619749), np.float64(0.0733643479203919), np.float64(0.07315122955375959), np.float64(0.07294146880042966), np.float64(0.07273500932279067), np.float64(0.07253179573511871), np.float64(0.07233177358748233), np.float64(0.0721348893499193), np.float64(0.07194109039688139), np.float64(0.07175032499194182), np.float64(0.07156254227276149), np.float64(0.07137769223630935), np.float64(0.07119572572433286), np.float64(0.07101659440907385), np.float64(0.07084025077922623), np.float64(0.070666648126131), np.float64(0.07049574053020462), np.float64(0.07032748284759716), np.float64(0.07016183069707572), np.float64(0.0699987404471299), np.float64(0.06983816920329523), np.float64(0.06968007479569092), np.float64(0.06952441576676843), np.float64(0.06937115135926715), np.float64(0.06922024150437375), np.float64(0.06907164681008185), np.float64(0.06892532854974835), np.float64(0.0687812486508435), np.float64(0.06863936968389095), np.float64(0.06849965485159508), np.float64(0.06836206797815195), np.float64(0.06822657349874123), np.float64(0.06809313644919561), np.float64(0.067961722455845), np.float64(0.06783229772553254), np.float64(0.06770482903579932), np.float64(0.06757928372523506), np.float64(0.06745562968399212), np.float64(0.06733383534445969), np.float64(0.06721386967209597), np.float64(0.06709570215641501), np.float64(0.06697930280212627), np.float64(0.06686464212042395), np.float64(0.06675169112042348), np.float64(0.0666404213007429), np.float64(0.06653080464122665), np.float64(0.06642281359480932), np.float64(0.06631642107951677), np.float64(0.06621160047060279), np.float64(0.06610832559281864), np.float64(0.06600657071281309), np.float64(0.0659063105316614), np.float64(0.06580752017752023), np.float64(0.06571017519840698), np.float64(0.06561425155510119), np.float64(0.06551972561416586), np.float64(0.06542657414108709), np.float64(0.06533477429352925), np.float64(0.06524430361470467), np.float64(0.06515514002685512), np.float64(0.06506726182484374), np.float64(0.06498064766985515), np.float64(0.06489527658320228), np.float64(0.06481112794023773), np.float64(0.06472818146436811), np.float64(0.0646464172211699), np.float64(0.06456581561260431), np.float64(0.06448635737133043), np.float64(0.0644080235551142), np.float64(0.06433079554133217), np.float64(0.06425465502156798), np.float64(0.06417958399630046), np.float64(0.06410556476968135), np.float64(0.06403257994440141), np.float64(0.0639606124166433), np.float64(0.06388964537111992), np.float64(0.06381966227619645), np.float64(0.06375064687909507), np.float64(0.06368258320118077), np.float64(0.06361545553332655), np.float64(0.06354924843135755), np.float64(0.06348394671157162), np.float64(0.06341953544633615), np.float64(0.06335599995975896), np.float64(0.06329332582343267), np.float64(0.06323149885225086), np.float64(0.06317050510029515), np.float64(0.06311033085679153), np.float64(0.06305096264213547), np.float64(0.06299238720398384), np.float64(0.0629345915134133), np.float64(0.06287756276114324), np.float64(0.06282128835382297), np.float64(0.0627657559103815), np.float64(0.06271095325843898), np.float64(0.06265686843077901), np.float64(0.06260348966188053), np.float64(0.06255080538450809), np.float64(0.06249880422636036), np.float64(0.06244747500677472), np.float64(0.06239680673348793), np.float64(0.06234678859945137), np.float64(0.06229740997970036), np.float64(0.0622486604282762), np.float64(0.06220052967520031), np.float64(0.062153007623499706), np.float64(0.062106084346282515), np.float64(0.062059750083863094), np.float64(0.06201399524093575), np.float64(0.06196881038379625), np.float64(0.061924186237610215), np.float64(0.06188011368372787), np.float64(0.0618365837570441), np.float64(0.06179358764340313), np.float64(0.061751116677047156), np.float64(0.06170916233810801), np.float64(0.0616677162501414), np.float64(0.06162677017770278), np.float64(0.061586316023964055), np.float64(0.0615463458283708), np.float64(0.06150685176433905), np.float64(0.06146782613699094), np.float64(0.0614292613809287), np.float64(0.061391150058046254), np.float64(0.06135348485537795), np.float64(0.06131625858298352), np.float64(0.061279464171868706), np.float64(0.06124309467194143), np.float64(0.061207143250002184), np.float64(0.06117160318776841), np.float64(0.06113646787993252), np.float64(0.061101730832252524), np.float64(0.06106738565967507), np.float64(0.06103342608449018), np.float64(0.06099984593451716), np.float64(0.06096663914132128), np.float64(0.0609337997384604), np.float64(0.0609013218597616), np.float64(0.06086919973762659), np.float64(0.06083742770136588), np.float64(0.06080600017556133), np.float64(0.06077491167845612), np.float64(0.06074415682037193), np.float64(0.06071373030215326), np.float64(0.060683626913637524), np.float64(0.06065384153215141), np.float64(0.06062436912103256), np.float64(0.0605952047281761), np.float64(0.06056634348460599), np.float64(0.060537780603070336), np.float64(0.060509511376660545), np.float64(0.0604815311774538), np.float64(0.060453835455178496), np.float64(0.06042641973590228), np.float64(0.06039927962074216), np.float64(0.060372410784596583), np.float64(0.060345808974898815), np.float64(0.06031947001039151), np.float64(0.06029338977992186), np.float64(0.06026756424125725), np.float64(0.060241989419920934), np.float64(0.06021666140804729), np.float64(0.0601915763632565), np.float64(0.06016673050754826), np.float64(0.060142120126214255), np.float64(0.06011774156676883), np.float64(0.06009359123789796), np.float64(0.06006966560842588), np.float64(0.06004596120629915), np.float64(0.060022474617588105), np.float64(0.059999202485504784), np.float64(0.059976141509438), np.float64(0.05995328844400421), np.float64(0.05993064009811483), np.float64(0.05990819333405906), np.float64(0.059885945066602345), np.float64(0.059863892262100066), np.float64(0.059842031937626106), np.float64(0.059820361160116395), np.float64(0.05979887704552664), np.float64(0.05977757675800453), np.float64(0.05975645750907579), np.float64(0.05973551655684408), np.float64(0.0597147512052044), np.float64(0.05969415880306974), np.float64(0.05967373674361096), np.float64(0.05965348246350928), np.float64(0.05963339344222168), np.float64(0.059613467201258485), np.float64(0.059593701303473294), np.float64(0.05957409335236496), np.float64(0.05955464099139111), np.float64(0.05953534190329372), np.float64(0.059516193809435625), np.float64(0.0594971944691485), np.float64(0.0594783416790919), np.float64(0.05945963327262296), np.float64(0.0594410671191769), np.float64(0.05942264112365792), np.float64(0.05940435322584049), np.float64(0.059386201399780576), np.float64(0.059368183653237094), np.float64(0.059350298027102844), np.float64(0.05933254259484533), np.float64(0.05931491546195686), np.float64(0.05929741476541398), np.float64(0.0592800386731462), np.float64(0.05926278538351338), np.float64(0.05924565312479226), np.float64(0.05922864015467154), np.float64(0.059211744759755505), np.float64(0.059194965255076046), np.float64(0.05917829998361292), np.float64(0.05916174731582212), np.float64(0.059145305649172315), np.float64(0.059128973407688926), np.float64(0.059112749041506096), np.float64(0.05909663102642617), np.float64(0.05908061786348662), np.float64(0.059064708078534194), np.float64(0.05904890022180654), np.float64(0.05903319286752055), np.float64(0.05901758461346795), np.float64(0.05900207408061755), np.float64(0.058986659912724324), np.float64(0.05897134077594505), np.float64(0.058956115358460404), np.float64(0.05894098237010357), np.float64(0.05892594054199501), np.float64(0.05891098862618344), np.float64(0.05889612539529293), np.float64(0.05888134964217589), np.float64(0.05886666017957195), np.float64(0.058852055839772675), np.float64(0.05883753547429179), np.float64(0.058823097953541174), np.float64(0.058808742166512155), np.float64(0.05879446702046235), np.float64(0.058780271440607684), np.float64(0.05876615436981961), np.float64(0.05875211476832761), np.float64(0.05873815161342641), np.float64(0.05872426389918856), np.float64(0.058710450636181515), np.float64(0.05869671085118971), np.float64(0.058683043586941104), np.float64(0.058669447901838714), np.float64(0.05865592286969638), np.float64(0.05864246757947903), np.float64(0.05862908113504752), np.float64(0.05861576265490756), np.float64(0.058602511271963004), np.float64(0.05858932613327336), np.float64(0.058576206399815284), np.float64(0.05856315124624814), np.float64(0.05855015986068357), np.float64(0.05853723144445888), np.float64(0.05852436521191438), np.float64(0.05851156039017436), np.float64(0.0584988162189318), np.float64(0.05848613195023677), np.float64(0.05847350684828838), np.float64(0.058460940189230176), np.float64(0.05844843126094919), np.float64(0.05843597936287807), np.float64(0.05842358380580092), np.float64(0.05841124391166213), np.float64(0.05839895901337858), np.float64(0.05838672845465502), np.float64(0.05837455158980245), np.float64(0.05836242778355972), np.float64(0.05835035641091811), np.float64(0.05833833685694878), np.float64(0.05832636851663321), np.float64(0.05831445079469655), np.float64(0.05830258310544367), np.float64(0.05829076487259809), np.float64(0.05827899552914358), np.float64(0.05826727451716845), np.float64(0.058255601287712386), np.float64(0.0582439753006161), np.float64(0.058232396024373266), np.float64(0.05822086293598511), np.float64(0.058209375520817355), np.float64(0.058197933272459756), np.float64(0.05818653569258779), np.float64(0.05817518229082684), np.float64(0.058163872584618616), np.float64(0.05815260609908985), np.float64(0.058141382366923164), np.float64(0.058130200928230166), np.float64(0.058119061330426776), np.float64(0.058107963128110396), np.float64(0.05809690588293942), np.float64(0.058085889163514745), np.float64(0.058074912545263056), np.float64(0.058063975610322414), np.float64(0.058053077947429504), np.float64(0.05804221915180897), np.float64(0.05803139882506447), np.float64(0.05802061657507169), np.float64(0.0580098720158732), np.float64(0.05799916476757483), np.float64(0.057988494456244134), np.float64(0.057977860713810364), np.float64(0.057967263177966154), np.float64(0.05795670149207094), np.float64(0.05794617530505593), np.float64(0.05793568427133074), np.float64(0.057925228050691516), np.float64(0.057914806308230836), np.float64(0.057904418714248757), np.float64(0.057894064944165734), np.float64(0.05788374467843681), np.float64(0.05787345760246728), np.float64(0.057863203406529826), np.float64(0.05785298178568306), np.float64(0.05784279243969133), np.float64(0.057832635072946004), np.float64(0.05782250939438805), np.float64(0.0578124151174319), np.float64(0.05780235195989063), np.float64(0.057792319643902336), np.float64(0.05778231789585793), np.float64(0.0577723464463298), np.float64(0.05776240503000217), np.float64(0.05775249338560223), np.float64(0.05774261125583255), np.float64(0.05773275838730474), np.float64(0.05772293453047407), np.float64(0.05771313943957533), np.float64(0.0577033728725597), np.float64(0.057693634591032654), np.float64(0.057683924360193005), np.float64(0.05767424194877295), np.float64(0.05766458712897906), np.float64(0.05765495967643434), np.float64(0.057645359370121226), np.float64(0.05763578599232564), np.float64(0.057626239328581796), np.float64(0.05761671916761811), np.float64(0.05760722530130401), np.float64(0.05759775752459752), np.float64(0.057588315635493874), np.float64(0.057578899434974906), np.float64(0.05756950872695933), np.float64(0.05756014331825381), np.float64(0.05755080301850501), np.float64(0.057541487640152184), np.float64(0.05753219699838088), np.float64(0.057522930911077144), np.float64(0.057513689198782685), np.float64(0.05750447168465076), np.float64(0.05749527819440267), np.float64(0.057486108556285255), np.float64(0.05747696260102877), np.float64(0.05746784016180581), np.float64(0.05745874107419066), np.float64(0.05744966517611951), np.float64(0.05744061230785123), np.float64(0.05743158231192885), np.float64(0.05742257503314173), np.float64(0.057413590318488285), np.float64(0.05740462801713937), np.float64(0.057395687980402336), np.float64(0.05738677006168561), np.float64(0.05737787411646401), np.float64(0.057369000002244354), np.float64(0.05736014757853204), np.float64(0.05735131670679789), np.float64(0.057342507250445686), np.float64(0.05733371907478018), np.float64(0.05732495204697581), np.float64(0.057316206036045626), np.float64(0.05730748091281111), np.float64(0.057298776549872255), np.float64(0.05729009282157824), np.float64(0.05728142960399854), np.float64(0.05727278677489465), np.float64(0.05726416421369212), np.float64(0.05725556180145319), np.float64(0.05724697942084986), np.float64(0.0572384169561373), np.float64(0.05722987429312795), np.float64(0.05722135131916572), np.float64(0.05721284792310103), np.float64(0.05720436399526589), np.float64(0.0571958994274496), np.float64(0.057187454112874896), np.float64(0.05717902794617434), np.float64(0.05717062082336728), np.float64(0.057162232641836994), np.float64(0.05715386330030848), np.float64(0.05714551269882637), np.float64(0.05713718073873334), np.float64(0.05712886732264895), np.float64(0.05712057235444866), np.float64(0.05711229573924336), np.float64(0.05710403738335914), np.float64(0.0570957971943175), np.float64(0.05708757508081579), np.float64(0.057079370952708035), np.float64(0.057071184720986066), np.float64(0.05706301629776107), np.float64(0.057054865596245175), np.float64(0.057046732530733744), np.float64(0.05703861701658757), np.float64(0.05703051897021566), np.float64(0.05702243830905818), np.float64(0.057014374951569684), np.float64(0.057006328817202634), np.float64(0.05699829982639134), np.float64(0.05699028790053585), np.float64(0.05698229296198646), np.float64(0.05697431493402824), np.float64(0.05696635374086599), np.float64(0.05695840930760929), np.float64(0.056950481560257914), np.float64(0.0569425704256875), np.float64(0.0569346758316353), np.float64(0.05692679770668645), np.float64(0.05691893598026014), np.float64(0.05691109058259633), np.float64(0.05690326144474244), np.float64(0.05689544849854041), np.float64(0.056887651676613984), np.float64(0.05687987091235604), np.float64(0.056872106139916355), np.float64(0.05686435729418944), np.float64(0.05685662431080263), np.float64(0.0568489071261043), np.float64(0.05684120567715239), np.float64(0.056833519901703065), np.float64(0.05682584973819958), np.float64(0.05681819512576124), np.float64(0.05681055600417275), np.float64(0.056802932313873525), np.float64(0.056795323995947306), np.float64(0.056787730992111936), np.float64(0.05678015324470926), np.float64(0.05677259069669528), np.float64(0.05676504329163035), np.float64(0.05675751097366966), np.float64(0.05674999368755382), np.float64(0.05674249137859953), np.float64(0.05673500399269066), np.float64(0.05672753147626912), np.float64(0.056720073776326194), np.float64(0.05671263084039382), np.float64(0.056705202616536096), np.float64(0.05669778905334098), np.float64(0.05669039009991206), np.float64(0.05668300570586036), np.float64(0.05667563582129657), np.float64(0.056668280396823104), np.float64(0.05666093938352648), np.float64(0.05665361273296975), np.float64(0.056646300397185066), np.float64(0.05663900232866641), np.float64(0.05663171848036241), np.float64(0.05662444880566923), np.float64(0.05661719325842369), np.float64(0.056609951792896414), np.float64(0.05660272436378514), np.float64(0.05659551092620811), np.float64(0.056588311435697584), np.float64(0.05658112584819342), np.float64(0.05657395412003692), np.float64(0.05656679620796451), np.float64(0.05655965206910184), np.float64(0.05655252166095763), np.float64(0.05654540494141801), np.float64(0.056538301868740586), np.float64(0.05653121240154893), np.float64(0.056524136498826864), np.float64(0.056517074119913024), np.float64(0.05651002522449555), np.float64(0.05650298977260663), np.float64(0.05649596772461748), np.float64(0.056488959041233064), np.float64(0.05648196368348717), np.float64(0.05647498161273735), np.float64(0.0564680127906601), np.float64(0.056461057179246134), np.float64(0.05645411474079556), np.float64(0.05644718543791332), np.float64(0.05644026923350467), np.float64(0.056433366090770515), np.float64(0.05642647597320331), np.float64(0.05641959884458242), np.float64(0.05641273466897008), np.float64(0.05640588341070717), np.float64(0.05639904503440896), np.float64(0.05639221950496121), np.float64(0.05638540678751615), np.float64(0.05637860684748858), np.float64(0.056371819650551894), np.float64(0.05636504516263454), np.float64(0.05635828334991603), np.float64(0.05635153417882347), np.float64(0.05634479761602789), np.float64(0.05633807362844066), np.float64(0.05633136218321008), np.float64(0.056324663247717996), np.float64(0.05631797678957624), np.float64(0.05631130277662355), np.float64(0.05630464117692215), np.float64(0.056297991958754665), np.float64(0.05629135509062089), np.float64(0.056284730541234666), np.float64(0.05627811827952098), np.float64(0.05627151827461283), np.float64(0.0562649304958483), np.float64(0.05625835491276777), np.float64(0.05625179149511093), np.float64(0.05624524021281401), np.float64(0.05623870103600713), np.float64(0.05623217393501149), np.float64(0.05622565888033667), np.float64(0.05621915584267811), np.float64(0.05621266479291449), np.float64(0.056206185702105234), np.float64(0.05619971854148787), np.float64(0.05619326328247578), np.float64(0.05618681989665565), np.float64(0.05618038835578517), np.float64(0.05617396863179063), np.float64(0.05616756069676472), np.float64(0.05616116452296419), np.float64(0.05615478008280768), np.float64(0.05614840734887347), np.float64(0.05614204629389748), np.float64(0.05613569689077096), np.float64(0.0561293591125386), np.float64(0.056123032932396344), np.float64(0.05611671832368947), np.float64(0.05611041525991056), np.float64(0.05610412371469758), np.float64(0.056097843661832), np.float64(0.05609157507523687), np.float64(0.05608531792897493), np.float64(0.05607907219724691), np.float64(0.056072837854389615), np.float64(0.05606661487487427), np.float64(0.05606040323330473), np.float64(0.056054202904415734), np.float64(0.05604801386307135), np.float64(0.056041836084263226), np.float64(0.056035669543109), np.float64(0.056029514214850695), np.float64(0.05602337007485319), np.float64(0.05601723709860266), np.float64(0.05601111526170498), np.float64(0.05600500453988435), np.float64(0.05599890490898177), np.float64(0.05599281634495359), np.float64(0.055986738823870105), np.float64(0.055980672321914095), np.float64(0.055974616815379595), np.float64(0.055968572280670384), np.float64(0.055962538694298715), np.float64(0.05595651603288404), np.float64(0.05595050427315166), np.float64(0.0559445033919315), np.float64(0.05593851336615685), np.float64(0.05593253417286313), np.float64(0.05592656578918666), np.float64(0.05592060819236354), np.float64(0.05591466135972839), np.float64(0.05590872526871329), np.float64(0.05590279989684662), np.float64(0.05589688522175184), np.float64(0.055890981221146614), np.float64(0.05588508787284151), np.float64(0.055879205154739084), np.float64(0.05587333304483278), np.float64(0.05586747152120588), np.float64(0.055861620562030555), np.float64(0.05585578014556684), np.float64(0.05584995025016163), np.float64(0.05584413085424776), np.float64(0.05583832193634303), np.float64(0.0558325234750493), np.float64(0.0558267354490515), np.float64(0.05582095783711688), np.float64(0.05581519061809395), np.float64(0.05580943377091164), np.float64(0.055803687274578614), np.float64(0.05579795110818212), np.float64(0.05579222525088745), np.float64(0.055786509681936956), np.float64(0.05578080438064925), np.float64(0.05577510932641848), np.float64(0.05576942449871346), np.float64(0.055763749877076975), np.float64(0.05575808544112503), np.float64(0.05575243117054599), np.float64(0.05574678704509999), np.float64(0.05574115304461813), np.float64(0.055735529149001775), np.float64(0.05572991533822185), np.float64(0.0557243115923182), np.float64(0.05571871789139883), np.float64(0.05571313421563932), np.float64(0.05570756054528211), np.float64(0.055701996860635865), np.float64(0.055696443142074864), np.float64(0.055690899370038335), np.float64(0.05568536552502988), np.float64(0.05567984158761686), np.float64(0.055674327538429685), np.float64(0.05566882335816142), np.float64(0.055663329027567085), np.float64(0.055657844527463085), np.float64(0.05565236983872668), np.float64(0.05564690494229538), np.float64(0.0556414498191665), np.float64(0.05563600445039652), np.float64(0.055630568817100635), np.float64(0.05562514290045211), np.float64(0.05561972668168197), np.float64(0.05561432014207832), np.float64(0.05560892326298588), np.float64(0.055603536025805575), np.float64(0.055598158411993996), np.float64(0.05559279040306291), np.float64(0.055587431980578784), np.float64(0.055582083126162425), np.float64(0.05557674382148841), np.float64(0.055571414048284674), np.float64(0.05556609378833211), np.float64(0.055560783023464094), np.float64(0.05555548173556606), np.float64(0.055550189906575106), np.float64(0.05554490751847952), np.float64(0.055539634553318486), np.float64(0.05553437099318153), np.float64(0.055529116820208266), np.float64(0.05552387201658793), np.float64(0.055518636564558965), np.float64(0.05551341044640875), np.float64(0.05550819364447313), np.float64(0.05550298614113609), np.float64(0.05549778791882936), np.float64(0.05549259896003212), np.float64(0.05548741924727061), np.float64(0.05548224876311773), np.float64(0.055477087490192804), np.float64(0.0554719354111612), np.float64(0.055466792508733924), np.float64(0.05546165876566746), np.float64(0.055456534164763226), np.float64(0.05545141868886745), np.float64(0.05544631232087083), np.float64(0.05544121504370806), np.float64(0.055436126840357744), np.float64(0.055431047693841926), np.float64(0.05542597758722593), np.float64(0.055420916503617974), np.float64(0.05541586442616892), np.float64(0.055410821338071965), np.float64(0.05540578722256242), np.float64(0.05540076206291734), np.float64(0.055395745842455345), np.float64(0.05539073854453634), np.float64(0.05538574015256118), np.float64(0.05538075064997147), np.float64(0.055375770020249314), np.float64(0.05537079824691705), np.float64(0.05536583531353694), np.float64(0.05536088120371103), np.float64(0.05535593590108084), np.float64(0.05535099938932713), np.float64(0.055346071652169704), np.float64(0.0553411526733671), np.float64(0.05533624243671647), np.float64(0.05533134092605322), np.float64(0.055326448125250914), np.float64(0.05532156401822096), np.float64(0.05531668858891247), np.float64(0.055311821821311946), np.float64(0.055306963699443185), np.float64(0.05530211420736701), np.float64(0.055297273329180996), np.float64(0.05529244104901939), np.float64(0.0552876173510529), np.float64(0.05528280221948834), np.float64(0.05527799563856866), np.float64(0.055273197592572584), np.float64(0.05526840806581448), np.float64(0.055263627042644155), np.float64(0.055258854507446706), np.float64(0.05525409044464235), np.float64(0.05524933483868614), np.float64(0.05524458767406786), np.float64(0.05523984893531189), np.float64(0.055235118606976955), np.float64(0.05523039667365596), np.float64(0.05522568311997589), np.float64(0.055220977930597534), np.float64(0.055216281090215466), np.float64(0.05521159258355773), np.float64(0.055206912395385714), np.float64(0.055202240510494154), np.float64(0.05519757691371069), np.float64(0.055192921589895944), np.float64(0.055188274523943294), np.float64(0.05518363570077869), np.float64(0.05517900510536053), np.float64(0.05517438272267951), np.float64(0.055169768537758505), np.float64(0.055165162535652366), np.float64(0.055160564701447826), np.float64(0.05515597502026334), np.float64(0.055151393477248956), np.float64(0.05514682005758613), np.float64(0.055142254746487665), np.float64(0.05513769752919755), np.float64(0.0551331483909908), np.float64(0.055128607317173346), np.float64(0.055124074293081866), np.float64(0.055119549304083755), np.float64(0.05511503233557687), np.float64(0.05511052337298953), np.float64(0.05510602240178027), np.float64(0.05510152940743782), np.float64(0.05509704437548093), np.float64(0.05509256729145828), np.float64(0.05508809814094827), np.float64(0.05508363690955906), np.float64(0.05507918358292834), np.float64(0.05507473814672324), np.float64(0.055070300586640204), np.float64(0.05506587088840496), np.float64(0.05506144903777225), np.float64(0.05505703502052585), np.float64(0.055052628822478474), np.float64(0.05504823042947156), np.float64(0.05504383982737522), np.float64(0.05503945700208816), np.float64(0.05503508193953754), np.float64(0.055030714625678864), np.float64(0.05502635504649593), np.float64(0.05502200318800065), np.float64(0.055017659036233034), np.float64(0.055013322577261034), np.float64(0.055008993797180404), np.float64(0.05500467268211479), np.float64(0.05500035921821539), np.float64(0.054996053391661005), np.float64(0.05499175518865794), np.float64(0.05498746459543984), np.float64(0.054983181598267664), np.float64(0.0549789061834296), np.float64(0.054974638337240846), np.float64(0.05497037804604376), np.float64(0.0549661252962075), np.float64(0.054961880074128146), np.float64(0.0549576423662285), np.float64(0.054953412158958034), np.float64(0.054949189438792796), np.float64(0.05494497419223534), np.float64(0.05494076640581463), np.float64(0.05493656606608597), np.float64(0.05493237315963089), np.float64(0.05492818767305708), np.float64(0.05492400959299837), np.float64(0.05491983890611449), np.float64(0.05491567559909121), np.float64(0.05491151965864005), np.float64(0.05490737107149833), np.float64(0.05490322982442909), np.float64(0.054899095904220915), np.float64(0.05489496929768798), np.float64(0.05489084999166989), np.float64(0.05488673797303166), np.float64(0.054882633228663574), np.float64(0.05487853574548118), np.float64(0.054874445510425175), np.float64(0.05487036251046136), np.float64(0.054866286732580524), np.float64(0.05486221816379847), np.float64(0.05485815679115577), np.float64(0.0548541026017179), np.float64(0.054850055582575), np.float64(0.05484601572084191), np.float64(0.0548419830036581), np.float64(0.05483795741818747), np.float64(0.05483393895161846), np.float64(0.0548299275911639), np.float64(0.054825923324060916), np.float64(0.05482192613757092), np.float64(0.05481793601897949), np.float64(0.05481395295559637), np.float64(0.05480997693475535), np.float64(0.05480600794381422), np.float64(0.0548020459701547), np.float64(0.054798091001182415), np.float64(0.05479414302432678), np.float64(0.054790202027040935), np.float64(0.05478626799680179), np.float64(0.05478234092110976), np.float64(0.05477842078748891), np.float64(0.0547745075834868), np.float64(0.054770601296674395), np.float64(0.05476670191464608), np.float64(0.05476280942501958), np.float64(0.054758923815435796), np.float64(0.05475504507355896), np.float64(0.05475117318707636), np.float64(0.0547473081436984), np.float64(0.05474344993115854), np.float64(0.054739598537213205), np.float64(0.054735753949641676), np.float64(0.05473191615624621), np.float64(0.05472808514485178), np.float64(0.054724260903306156), np.float64(0.05472044341947975), np.float64(0.05471663268126573), np.float64(0.05471282867657969), np.float64(0.0547090313933599), np.float64(0.05470524081956701), np.float64(0.05470145694318413), np.float64(0.05469767975221677), np.float64(0.054693909234692674), np.float64(0.05469014537866194), np.float64(0.05468638817219683), np.float64(0.05468263760339178), np.float64(0.05467889366036329), np.float64(0.05467515633125), np.float64(0.05467142560421251), np.float64(0.05466770146743334), np.float64(0.054663983909116975), np.float64(0.054660272917489705), np.float64(0.05465656848079964), np.float64(0.05465287058731666), np.float64(0.05464917922533233), np.float64(0.05464549438315985), np.float64(0.054641816049134054), np.float64(0.05463814421161133), np.float64(0.05463447885896955), np.float64(0.05463081997960807), np.float64(0.05462716756194763), np.float64(0.05462352159443039), np.float64(0.054619882065519716), np.float64(0.054616248963700355), np.float64(0.05461262227747823), np.float64(0.05460900199538041), np.float64(0.054605388105955124), np.float64(0.054601780597771675), np.float64(0.05459817945942039), np.float64(0.05459458467951261), np.float64(0.05459099624668059), np.float64(0.05458741414957748), np.float64(0.0545838383768773), np.float64(0.054580268917274875), np.float64(0.05457670575948582), np.float64(0.05457314889224635), np.float64(0.054569598304313474), np.float64(0.0545660539844648), np.float64(0.054562515921498494), np.float64(0.05455898410423328), np.float64(0.054555458521508345), np.float64(0.05455193916218337), np.float64(0.05454842601513845), np.float64(0.05454491906927401), np.float64(0.05454141831351079), np.float64(0.054537923736789846), np.float64(0.054534435328072464), np.float64(0.0545309530763401), np.float64(0.054527476970594374), np.float64(0.054524006999857044), np.float64(0.054520543153169884), np.float64(0.05451708541959473), np.float64(0.054513633788213396), np.float64(0.054510188248127645), np.float64(0.05450674878845912), np.float64(0.05450331539834934), np.float64(0.054499888066959656), np.float64(0.05449646678347117), np.float64(0.054493051537084725), np.float64(0.05448964231702087), np.float64(0.05448623911251984), np.float64(0.05448284191284145), np.float64(0.054479450707265106), np.float64(0.05447606548508972), np.float64(0.054472686235633755), np.float64(0.054469312948235114), np.float64(0.0544659456122511), np.float64(0.05446258421705838), np.float64(0.05445922875205301), np.float64(0.05445587920665035), np.float64(0.05445253557028493), np.float64(0.05444919783241064), np.float64(0.05444586598250044), np.float64(0.054442540010046496), np.float64(0.05443921990456002), np.float64(0.0544359056555714), np.float64(0.054432597252629965), np.float64(0.05442929468530409), np.float64(0.054425997943181044), np.float64(0.05442270701586708), np.float64(0.05441942189298729), np.float64(0.05441614256418564), np.float64(0.05441286901912488), np.float64(0.05440960124748651), np.float64(0.054406339238970806), np.float64(0.05440308298329671), np.float64(0.054399832470201845), np.float64(0.054396587689442416), np.float64(0.054393348630793245), np.float64(0.05439011528404767), np.float64(0.05438688763901759), np.float64(0.054383665685533336), np.float64(0.0543804494134437), np.float64(0.054377238812615865), np.float64(0.05437403387293539), np.float64(0.054370834584306166), np.float64(0.05436764093665037), np.float64(0.054364452919908414), np.float64(0.05436127052403898), np.float64(0.05435809373901896)]\n"
     ]
    }
   ],
   "source": [
    "# To-Do-6\n",
    "import numpy as np\n",
    "def gradient_descent(X,Y,W,alpha = 0.01, iterations = 10):\n",
    "\"\"\"\n",
    "Perform gradient descent to optimize the parameters of a linear regression model.\n",
    "Parameters:\n",
    "X (numpy.ndarray): Feature matrix (m x n).\n",
    "Y (numpy.ndarray): Target vector (m x 1).\n",
    "W (numpy.ndarray): Initial guess for parameters (n x 1).\n",
    "alpha (float): Learning rate.\n",
    "iterations (int): Number of iterations for gradient descent.\n",
    "Returns:\n",
    "\n",
    "tuple: A tuple containing the final optimized parameters (W_update) and the history of cost values\n",
    ".\n",
    "W_update (numpy.ndarray): Updated parameters (n x 1).\n",
    "cost_history (list): History of cost values over iterations.\n",
    "\"\"\"\n",
    "    X = np.array(X, dtype = float)\n",
    "    Y = np.array(Y, dtype = float).reshape(-1,1)\n",
    "    W = np.array(W, dtype = float).reshape(-1,1)\n",
    "    m = len(Y) #Number of samples\n",
    "    cost_history = [0] * iterations #To store cost at each iteration\n",
    "    W_update = W.copy()\n",
    "\n",
    "    for iteration in range(iterations):\n",
    "        #Step-1: Hypothesis values\n",
    "        Y_pred = X @ W_update\n",
    "        #Step-2: Difference between hypothesis and actual Y\n",
    "        loss = Y_pred - Y\n",
    "        #Step-3: Gradient calculation\n",
    "        dw = (1/m) * (X.T @ loss)\n",
    "\n",
    "        #Step-4: Update W\n",
    "        W_update = W_update - alpha * dw\n",
    "\n",
    "        #Step-5: Compute new cost:\n",
    "        cost = (1/(2*m)) * np.sum(loss ** 2)\n",
    "        cost_history[iteration] = cost\n",
    "\n",
    "        if iteration % 100 == 0 or iteration == -1:\n",
    "            print(f\"Iteration {iteration}: Cost = {cost}\")\n",
    "\n",
    "    return W_update, cost_history\n",
    "\n",
    "#To-Do-7\n",
    "#Generate random test data\n",
    "np.random.seed(0)#For reproducibility\n",
    "X = np.random.rand(100,3)#100 samples, 3 features\n",
    "Y = np.random.rand(100)\n",
    "W = np.random.rand(3)#Initial guess for parameters\n",
    "\n",
    "#Set Hyperparameters\n",
    "alpha = 0.01\n",
    "iterations = 1000\n",
    "\n",
    "#Test the gradient_descent function\n",
    "final_params, cost_history = gradient_descent(X,Y,W,alpha,iterations)\n",
    "#Print the final parameters and cost history\n",
    "print(\"Final Parameters:\", final_params)\n",
    "print(\"Cost History:\", cost_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2e656097-ef82-4e6b-b2a8-32513be116d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To-Do-8\n",
    "def predict(X,W):\n",
    "    \"\"\"This function predicts the dependent variable using linear regression parameters.\n",
    "    Input Arguments:\n",
    "    X : Feature Matrix\n",
    "    W : Weight vector\n",
    "    Output Arguments:\n",
    "    Y_pred : Predicted values\n",
    "    \"\"\"\n",
    "    X = np.array(X, dtype = float)\n",
    "    W = np.array(W, dtype = float)\n",
    "    return X @ W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9d856d46-9ac9-47a6-899e-f9747bc74aca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.32971176064812524\n"
     ]
    }
   ],
   "source": [
    "def rmse(Y, Y_pred):\n",
    "    \"\"\"This function calculates the Root Mean Squares.\n",
    "    Input Arguments:\n",
    "    Y : Array of acutal(Target) Dependent Variables.\n",
    "    Y_pred : Array of predicted Dependent Variables.\n",
    "    Output Arguments : \n",
    "    rmse : Root Mean Square.\n",
    "    \"\"\"\n",
    "    Y = np.array(Y).reshape(-1,1)\n",
    "    Y_pred = np.array(Y_pred).reshape(-1,1)\n",
    "    rmse = np.sqrt(np.mean((Y-Y_pred) ** 2))\n",
    "    return rmse\n",
    "error = rmse(Y,Y_pred)\n",
    "print(\"RMSE:\", error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "64371ecc-04c5-4d89-b471-1d24e4c3b094",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 Score: -0.34175367492079367\n"
     ]
    }
   ],
   "source": [
    "# To-Do-9\n",
    "def r2_score(Y,Y_pred):\n",
    "    \"\"\"\n",
    "    This function calculates the R Squared Error.\n",
    "    Input Arguments:\n",
    "    Y: Array of actual (Target) Dependent Variables.\n",
    "    Y_pred : Array of predicted Dependent Variables.\n",
    "    Output Arguments:\n",
    "    rsquared : R Squared Error.\n",
    "    \"\"\"\n",
    "    Y = np.array(Y).reshape(-1,1)\n",
    "    Y_pred = np.array(Y_pred).reshape(-1,1)\n",
    "    mean_y = np.mean(Y)\n",
    "    ss_tot = np.sum ((Y - np.mean(Y)) ** 2)\n",
    "    ss_res = np.sum((Y - Y_pred) ** 2)\n",
    "    rsquared = 1 - (ss_res / ss_tot)\n",
    "    return r2\n",
    "Y_pred = predict(X,final_params)\n",
    "r2 = r2_score(Y,Y_pred)\n",
    "print(\"R2 Score:\",r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "af1d12b0-62b8-4333-9b10-d6a7f0a9279e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0: Cost = 2462.963125\n",
      "Iteration 100: Cost = 16.548978351242322\n",
      "Iteration 200: Cost = 16.058229712959054\n",
      "Iteration 300: Cost = 15.607070897089123\n",
      "Iteration 400: Cost = 15.192305852584742\n",
      "Iteration 500: Cost = 14.810998791542376\n",
      "Iteration 600: Cost = 14.460450748192903\n",
      "Iteration 700: Cost = 14.138180475095362\n",
      "Iteration 800: Cost = 13.84190688038349\n",
      "Iteration 900: Cost = 13.56953288175244\n",
      "Final Weights: [[0.3533225 ]\n",
      " [0.64122757]]\n",
      "Cost History (First 10 iterations): [np.float64(2462.963125), np.float64(2006.8394800833137), np.float64(1635.7746633286317), np.float64(1333.906546600848), np.float64(1088.331038315821), np.float64(888.5504563091041), np.float64(726.0247704585537), np.float64(593.8065314752632), np.float64(486.2438797132196), np.float64(398.7389381486675)]\n",
      "RMSE on the Test Set: 5.258385317376058\n",
      "R-Squared on Test Set: -0.34175367492079367\n"
     ]
    }
   ],
   "source": [
    "# To-Do-10\n",
    "# Main Function\n",
    "import pandas as pd\n",
    "def train_test_split(X, Y, test_size=0.2,random_state = 42):\n",
    "    np.random.seed(random_state)\n",
    "    X = np.array(X)\n",
    "    Y = np.array(Y)\n",
    "\n",
    "    indices = np.arange(len(X))\n",
    "    np.random.shuffle(indices)\n",
    "    X = X[indices]\n",
    "    Y = Y[indices]\n",
    "    \n",
    "    split_index = int (len(X) * (1 - test_size))\n",
    "    X_train = X[:split_index]\n",
    "    X_test = X[split_index:]\n",
    "    Y_train = Y[:split_index]\n",
    "    Y_test = Y[split_index:]\n",
    "\n",
    "    return X_train, X_test, Y_train, Y_test\n",
    "\n",
    "def main():\n",
    "    #Step-1: Load the database\n",
    "    data = pd.read_csv(\"C:/Users/Natsu Rohit/Downloads/student.csv\")\n",
    "    \n",
    "    #Step-2: Split the data into features [X] and target [Y]\n",
    "    X = data[['Math','Reading']].values #Features: Math and Reading marks\n",
    "    Y = data['Writing'].values #Target Writing Marks\n",
    "\n",
    "    #Step-3: Split the data into training and testing sets (80% train, 20% test)\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "    \n",
    "    #Step-4: Initialize the weights(W) to zeros, learning rate and number of iterations\n",
    "    W = np.zeros(X_train.shape[1])\n",
    "    alpha = 0.00001 #Learning rate\n",
    "    iterations = 1000 #Number of iterations for gradient descent\n",
    "\n",
    "    #Step-5: Perform Gradient Descent\n",
    "    W_optimal, cost_history = gradient_descent(X_train, Y_train, W, alpha, iterations)\n",
    "\n",
    "    #Step-6: Make predictions on the test set\n",
    "    Y_pred = np.dot(X_test, W_optimal)\n",
    "\n",
    "    #Step-7: Evaluate the model using RMSE and R-Squared\n",
    "    model_rmse = rmse(Y_test, Y_pred)\n",
    "    model_r2 = r2_score(Y_test, Y_pred)\n",
    "\n",
    "    #Step-8: Output the results\n",
    "    print(\"Final Weights:\",W_optimal)\n",
    "    print(\"Cost History (First 10 iterations):\", cost_history[:10])\n",
    "    print(\"RMSE on the Test Set:\", model_rmse)\n",
    "    print(\"R-Squared on Test Set:\", model_r2)\n",
    "\n",
    "#Execute the main function\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "737b326a-ed32-4813-b274-ede1586b57ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "#To-Do-11\n",
    "#1:\n",
    "\"\"\"\n",
    "Thus since the RMSE on the Test Set is 5.25 and R^2 on the Test Set is -0.34 which is\n",
    "negative and RMSE is moderate so the model is underfitting i.e, it hasn't learned the\n",
    "relationship between Math, Reading and Writing marks effectively.\n",
    "\"\"\"\n",
    "#2:\n",
    "\"\"\"\n",
    "Effect of learning rate :\n",
    "Increasing the value of alpha to 0.0001 improved convergence and slightly improved R-Squared.\n",
    "Decreasing alpha slowed convergence, and the model learned even less.\n",
    "Too high learning rate i.e, at 0.001 caused divergence or oscillations in the cost.\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
